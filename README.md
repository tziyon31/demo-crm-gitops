# Demo CRM GitOps Repository

> **Production-ready GitOps repository** for managing Demo CRM infrastructure, applications, monitoring, and observability using ArgoCD

[![ArgoCD](https://img.shields.io/badge/ArgoCD-2.8+-EF4444?logo=argo)](https://argo-cd.readthedocs.io/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-1.24+-326CE5?logo=kubernetes)](https://kubernetes.io/)
[![Helm](https://img.shields.io/badge/Helm-3.8+-0F1689?logo=helm)](https://helm.sh/)
[![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-E6522C?logo=prometheus)](https://prometheus.io/)
[![Grafana](https://img.shields.io/badge/Grafana-Dashboards-F46800?logo=grafana)](https://grafana.com/)
[![Elasticsearch](https://img.shields.io/badge/Elasticsearch-Logging-005571?logo=elasticsearch)](https://www.elastic.co/elasticsearch/)
[![Fluent Bit](https://img.shields.io/badge/Fluent_Bit-Log_Forwarder-49BDA5?logo=fluentbit)](https://fluentbit.io/)
[![Kibana](https://img.shields.io/badge/Kibana-Dashboards-E8478B?logo=kibana)](https://www.elastic.co/kibana/)

---

## üéØ Overview

This repository implements a **GitOps-based infrastructure, application, logging, and monitoring management system** using ArgoCD.

It follows the **App of Apps pattern** with a clean hierarchy for managing:

- Infrastructure components (ingress, TLS, database)
- Applications (Demo CRM, Rando, Juice Shop)
- Logging stack (EFK ‚Äî Elasticsearch, Fluent Bit, Kibana)
- Monitoring stack (Prometheus & Grafana)
- Dashboards and alerting

### Key Features

- ‚úÖ Production-ready deployment configuration
- ‚úÖ High availability with configurable replicas
- ‚úÖ Automatic TLS via cert-manager + Let's Encrypt
- ‚úÖ MongoDB replica set via Community Operator
- ‚úÖ GitOps-ready ArgoCD deployment with self-healing
- ‚úÖ Centralized logging via EFK stack
- ‚úÖ Full cluster monitoring via Prometheus + Grafana
- ‚úÖ Tiered dashboard design for operations visibility
- ‚úÖ Configurable resources and scaling

---

## üìÅ Repository Structure

```
demo-crm-gitops/
‚îú‚îÄ‚îÄ apps/                                    # ArgoCD Applications
‚îÇ   ‚îú‚îÄ‚îÄ app-of-apps.yaml                    # Root application (root-apps)
‚îÇ   ‚îú‚îÄ‚îÄ infra-root.yaml                     # Infrastructure root application
‚îÇ   ‚îú‚îÄ‚îÄ demo-crm-helm.yaml                 # Demo CRM application
‚îÇ   ‚îú‚îÄ‚îÄ demo-crm-juice-shop.yaml           # Juice Shop application
‚îÇ   ‚îú‚îÄ‚îÄ rando.yaml                          # Rando application
‚îÇ   ‚îî‚îÄ‚îÄ infra/                              # Infrastructure applications
‚îÇ       ‚îú‚îÄ‚îÄ namespaces-app.yaml
‚îÇ       ‚îú‚îÄ‚îÄ ingress-nginx-classic-app.yaml
‚îÇ       ‚îú‚îÄ‚îÄ infra-cert-manager.yaml
‚îÇ       ‚îú‚îÄ‚îÄ infra-clusterissuer.yaml
‚îÇ       ‚îú‚îÄ‚îÄ infra-mongodb-operator.yaml
‚îÇ       ‚îú‚îÄ‚îÄ infra-mongodb-community.yaml
‚îÇ       ‚îú‚îÄ‚îÄ infra-kube-prometheus-stack.yaml # Monitoring (Prometheus + Grafana)
‚îÇ       ‚îú‚îÄ‚îÄ infra-juiceshop-servicemonitor.yaml # ServiceMonitor for Juice Shop
‚îÇ       ‚îú‚îÄ‚îÄ infra-elasticsearch.yaml         # Logging backend
‚îÇ       ‚îú‚îÄ‚îÄ infra-fluent-bit.yaml            # Log forwarder
‚îÇ       ‚îî‚îÄ‚îÄ infra-kibana.yaml                # Log visualization
‚îú‚îÄ‚îÄ infra-apps/                              # Infrastructure charts & manifests
‚îÇ   ‚îú‚îÄ‚îÄ charts/                             # Helm charts for infrastructure
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cert-manager/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ community-operator/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ community-operator-crds/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ elasticsearch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fluent-bit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingress-nginx-classic/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kibana/
‚îÇ   ‚îú‚îÄ‚îÄ manifests/                          # Raw Kubernetes manifests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cert-manager/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitoring/                     # ServiceMonitor for Juice Shop
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mongodb/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ namespaces/
‚îÇ   ‚îî‚îÄ‚îÄ values/                             # External Helm chart values
‚îÇ       ‚îú‚îÄ‚îÄ juice-shop/
‚îÇ       ‚îî‚îÄ‚îÄ kube-prometheus-stack/
‚îî‚îÄ‚îÄ argocd-install/                          # ArgoCD installation manifests
    ‚îî‚îÄ‚îÄ argo-cd/
```

---

## üèóÔ∏è Architecture

### Application Hierarchy

```
root-apps (Root Application)
‚îú‚îÄ‚îÄ infra-root (Infrastructure Root)
‚îÇ   ‚îú‚îÄ‚îÄ infra-namespaces
‚îÇ   ‚îú‚îÄ‚îÄ infra-ingress-nginx-classic
‚îÇ   ‚îú‚îÄ‚îÄ infra-cert-manager
‚îÇ   ‚îú‚îÄ‚îÄ infra-clusterissuer
‚îÇ   ‚îú‚îÄ‚îÄ infra-mongodb-operator
‚îÇ   ‚îú‚îÄ‚îÄ infra-mongodb-community
‚îÇ   ‚îú‚îÄ‚îÄ infra-kube-prometheus-stack    ‚Üê Monitoring
‚îÇ   ‚îú‚îÄ‚îÄ infra-juiceshop-servicemonitor ‚Üê Monitoring
‚îÇ   ‚îú‚îÄ‚îÄ infra-elasticsearch            ‚Üê Logging
‚îÇ   ‚îú‚îÄ‚îÄ infra-fluent-bit               ‚Üê Logging
‚îÇ   ‚îî‚îÄ‚îÄ infra-kibana                   ‚Üê Logging
‚îú‚îÄ‚îÄ demo-crm-helm (Application)
‚îú‚îÄ‚îÄ demo-crm-juice-shop (Application)
‚îî‚îÄ‚îÄ rando (Application)
```

### Infrastructure Components

| Component | Purpose | Namespace |
|---|---|---|
| **ingress-nginx-classic** | Ingress controller (Kubernetes community) | `ingress-nginx-classic` |
| **cert-manager** | TLS certificate management | `cert-manager` |
| **ClusterIssuer** | Let's Encrypt certificate issuer | `cert-manager` |
| **MongoDB Operator** | MongoDB Community Operator | `demo-crm` |
| **MongoDB Community** | MongoDB replica set | `demo-crm` |
| **Prometheus** | Metrics collection & alerting rules | `monitoring` |
| **Grafana** | Dashboards, visualization & alerting | `monitoring` |
| **Juice Shop ServiceMonitor** | Exposes Juice Shop metrics to Prometheus | `monitoring` |
| **Elasticsearch** | Search & analytics engine (logging backend) | `logging` |
| **Fluent Bit** | Lightweight log forwarder (DaemonSet) | `logging` |
| **Kibana** | Log visualization & dashboards | `logging` |

---

## üìä Monitoring Stack (Prometheus & Grafana)

The monitoring stack is deployed using **kube-prometheus-stack** (v65.1.0) in the `monitoring` namespace.

### Prometheus

- Collects metrics from Kubernetes nodes, pods, services, ingress, and applications
- Enables cluster-wide visibility into resource usage and health
- Evaluates alerting rules for proactive incident detection

### Grafana

- Pre-configured dashboards for cluster and application monitoring
- Alerting rules with severity-based routing
- Tiered dashboard design for operations visibility (see [Observability](#-observability--dashboards))

### Service Monitoring

Applications that expose a `/metrics` endpoint (e.g. Juice Shop) are scraped automatically via **ServiceMonitor** resources registered with Prometheus.

---

## üìù EFK Logging Stack

The EFK (Elasticsearch, Fluent Bit, Kibana) stack is deployed in the `logging` namespace.

### Elasticsearch

- Single-node cluster with TLS enabled
- Stores all cluster logs collected by Fluent Bit

### Fluent Bit

- DaemonSet collecting container and systemd logs from every node
- Uses polling mode (`Inotify_Watcher Off`) for broad platform compatibility

### Kibana

- Connects to Elasticsearch via service account token
- **PostSync hook Job** automatically:
  1. Creates an Elasticsearch service account token
  2. Stores it in a Kubernetes secret
  3. Configures role mappings
  4. Restarts Kibana to pick up the token

---

## üöÄ Quick Start

### Prerequisites

- Kubernetes cluster (1.24+)
- ArgoCD installed and configured
- Access to the cluster with `kubectl`

### Installation

1. **Bootstrap ArgoCD** (if not already installed):

   ```bash
   kubectl apply -f argocd-install/
   ```

2. **Create root-apps Application**:

   ```bash
   kubectl apply -f apps/app-of-apps.yaml
   ```

3. **Verify deployment**:

   ```bash
   kubectl -n argocd get applications
   ```

4. **Verify monitoring stack**:

   ```bash
   kubectl get pods -n monitoring
   ```

5. **Verify logging stack**:

   ```bash
   kubectl get pods -n logging
   ```

### Sync Operations

```bash
# Sync all applications
argocd app sync root-apps

# Sync with prune (use with caution)
argocd app sync root-apps --prune

# Check application status
argocd app get root-apps
```

---

## ‚öôÔ∏è Configuration

### Root Application (`root-apps`)

| Setting | Value |
|---|---|
| Path | `apps/` |
| Recurse | `false` (explicit include pattern) |
| Includes | `infra-root.yaml`, `demo-crm-helm.yaml`, `demo-crm-juice-shop.yaml`, `rando.yaml` |
| Sync Policy | Automated with self-healing (prune disabled for safety) |

### Infrastructure Root (`infra-root`)

| Setting | Value |
|---|---|
| Path | `apps/infra/` |
| Recurse | `true` (discovers all infra applications) |
| Sync Policy | Automated with prune and self-healing |

---

## üîí Security & Best Practices

- **Prune Policy** ‚Äî Only enabled on infrastructure root (`infra-root`); disabled on `root-apps` for safety
- **Self-Healing** ‚Äî Enabled on all applications for automatic drift recovery
- **Namespace Isolation** ‚Äî Each component deployed to a dedicated namespace
- **TLS/HTTPS** ‚Äî Automatic certificate management via cert-manager + Let's Encrypt
- **Elasticsearch TLS** ‚Äî Internal communication secured with auto-generated certificates
- **Kibana Encryption** ‚Äî `xpack.encryptedSavedObjects.encryptionKey` set for alerting and saved object encryption
- **ServerSideApply** ‚Äî Enabled on Prometheus stack and Juice Shop to avoid field-manager conflicts

---

## üìä Observability & Dashboards

The system provides both **metrics monitoring** (Prometheus ‚Üí Grafana) and **centralized logging** (Fluent Bit ‚Üí Elasticsearch ‚Üí Kibana).

Dashboards follow the **Tiered Dashboard Design** approach.

### Tier 1 ‚Äî High-Level Overview

- Cluster health and node status
- Total log volume over time
- Traffic trends across namespaces
- Quick visibility into cluster-wide behavior

### Tier 2 ‚Äî Operations Dashboard

Used by DevOps / on-call engineers for deeper analysis:

- CPU saturation and memory usage
- Disk space utilization
- Request rate, error rate, latency (RED metrics)
- Log activity comparison across namespaces
- Color distribution of Rando events

### Alerting Dashboard

Dedicated dashboard with metrics that trigger alerts:

| Severity | Example Condition |
|---|---|
| **Critical** | CPU > 95% |
| **Warning** | Disk free < 20% |
| **Info** | Error rate > 1% |

Alerts are evaluated periodically by Grafana and routed via configured contact points.

### Error Investigation Panels

**Discover-based panels** embedded in Kibana dashboards allow:

- Viewing the latest logs directly
- Sorting by timestamp
- Quickly identifying recent errors
- Correlating events across namespaces and components

Used as a **fast troubleshooting entry point** instead of navigating manually to Discover.

### Red Event Percentage Metric

A custom metric visualization calculates the percentage of logs containing `rando_details.color = "red"`:

```
count(kql='rando_details.color:"red"') / count()
```

- Displays the percentage value with color thresholds
- Turns red when exceeding alert thresholds
- Provides an immediate signal of abnormal red-event rates

### Pending Dashboard Enhancements

- Traffic split visualization between Demo CRM and Kibana via ingress logs
- Unique MongoDB log counting visualization

---

## üìà Application Status

```bash
# List all applications
kubectl -n argocd get applications

# View application tree
argocd app get root-apps --show-tree

# Check sync status
argocd app list

# Check monitoring stack
kubectl get pods -n monitoring

# Check logging stack
kubectl get pods -n logging
```

---

## üîÑ GitOps Workflow

1. **Make changes** to manifests/charts in this repository
2. **Commit and push** to the main branch
3. **ArgoCD detects** changes automatically
4. **Applications sync** based on sync policy
5. **Monitor** via ArgoCD UI, Grafana dashboards, and Kibana logs

---

## üõ†Ô∏è Troubleshooting

### Application Not Syncing

```bash
# Check application status
argocd app get <app-name>

# Force refresh
argocd app get <app-name> --refresh

# View application logs
argocd app logs <app-name>
```

### Monitoring Issues

```bash
# Check monitoring pods
kubectl get pods -n monitoring

# Prometheus logs
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus --tail=50

# Grafana logs
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana --tail=50
```

### Logging Issues

```bash
# Elasticsearch health
kubectl exec -n logging elasticsearch-master-0 -- curl -sk https://localhost:9200/_cluster/health?pretty

# Fluent Bit pods
kubectl get pods -n logging -l app.kubernetes.io/name=fluent-bit

# Kibana logs
kubectl logs -n logging -l app=kibana --tail=50

# Kibana setup hook job
kubectl get jobs -n logging
```

### General Infrastructure

```bash
# Check infra applications
kubectl -n argocd get applications | grep infra

# Verify resources in a namespace
kubectl get all -n <namespace>
```

---

## üìö Related Repositories

- **[demo-crm-helm](https://github.com/tziyon31/demo-crm-helm)** ‚Äî Helm chart for the Demo CRM application

---

**Maintained by**: [tziyon31](https://github.com/tziyon31)  
**Repository**: [demo-crm-gitops](https://github.com/tziyon31/demo-crm-gitops)
